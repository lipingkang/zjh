{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating networks and loading parameters\n",
      "Model directory: ./20170512-110547\n",
      "Metagraph file: model-20170512-110547.meta\n",
      "Checkpoint file: model-20170512-110547.ckpt-250000\n",
      "WARNING:tensorflow:The saved meta_graph is possibly from an older release:\n",
      "'model_variables' collection should be of type 'byte_list', but instead is of type 'node_list'.\n",
      "INFO:tensorflow:Restoring parameters from ./20170512-110547\\model-20170512-110547.ckpt-250000\n",
      "folder:dilireba,image numbers：1\n",
      "folder:mylove,image numbers：1\n",
      "folder:other,image numbers：1\n",
      "folder:sanshu,image numbers：1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\scipy\\misc\\pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "E:\\anaconda\\lib\\site-packages\\scipy\\misc\\pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import cv2\n",
    "import csv\n",
    "from os.path import join as pjoin\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics  \n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "\n",
    "from scipy import misc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import argparse\n",
    "import facenet\n",
    "import align.detect_face\n",
    "\n",
    "\n",
    "\n",
    "minsize = 20 # minimum size of face\n",
    "threshold = [ 0.6, 0.7, 0.7 ]  # three steps's threshold\n",
    "factor = 0.709 # scale factor\n",
    "\n",
    "# 创建mtcnn网络，并加载参数\n",
    "print('Creating networks and loading parameters')\n",
    "with tf.Graph().as_default():\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "    with sess.as_default():\n",
    "        pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\n",
    "\n",
    "def load_and_align_data(image, image_size, margin, gpu_memory_fraction):\n",
    "\n",
    "    # 读取图片 \n",
    "    img = image\n",
    "    # 获取图片的shape\n",
    "    img_size = np.asarray(img.shape)[0:2]\n",
    "    # 返回边界框数组 （参数分别是输入图片 脸部最小尺寸 三个网络 阈值 factor不清楚）\n",
    "    bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n",
    "\n",
    "    # 如果检测出图片中不存在人脸 则直接返回，return 0（表示不存在人脸，跳过此图）\n",
    "    if len(bounding_boxes) < 1:\n",
    "        return 0,0,0\n",
    "    else:\n",
    "        crop=[]\n",
    "        det=bounding_boxes\n",
    "\n",
    "        det[:,0]=np.maximum(det[:,0], 0)\n",
    "        det[:,1]=np.maximum(det[:,1], 0)\n",
    "        det[:,2]=np.minimum(det[:,2], img_size[1])\n",
    "        det[:,3]=np.minimum(det[:,3], img_size[0])\n",
    "\n",
    "        # det[:,0]=np.maximum(det[:,0]-margin/2, 0)\n",
    "        # det[:,1]=np.maximum(det[:,1]-margin/2, 0)\n",
    "        # det[:,2]=np.minimum(det[:,2]+margin/2, img_size[1])\n",
    "        # det[:,3]=np.minimum(det[:,3]+margin/2, img_size[0])\n",
    "\n",
    "        det=det.astype(int)\n",
    "\n",
    "        for i in range(len(bounding_boxes)):\n",
    "            temp_crop=img[det[i,1]:det[i,3],det[i,0]:det[i,2],:]\n",
    "            aligned=misc.imresize(temp_crop, (image_size, image_size), interp='bilinear')\n",
    "            prewhitened = facenet.prewhiten(aligned)\n",
    "            crop.append(prewhitened)\n",
    "        crop_image=np.stack(crop)\n",
    "            \n",
    "        return det,crop_image,1\n",
    "\n",
    "    # np.squeeze() 降维，指定第几维，如果那个维度不是1  则无法降维\n",
    "    # det = np.squeeze(bounding_boxes[0,0:4])\n",
    "def to_rgb(img):\n",
    "    w, h = img.shape\n",
    "    ret = np.empty((w, h, 3), dtype=np.uint8)\n",
    "    ret[:, :, 0] = ret[:, :, 1] = ret[:, :, 2] = img\n",
    "    return ret\n",
    "\n",
    "\n",
    "def load_data(data_dir):\n",
    "\n",
    "    # data为字典类型 key对应人物分类 value为读取的一个人的所有图片 类型为ndarray\n",
    "    data = {}\n",
    "    pics_ctr = 0\n",
    "    for guy in os.listdir(data_dir):\n",
    "        person_dir = pjoin(data_dir, guy)       \n",
    "        curr_pics = [read_img(person_dir, f) for f in os.listdir(person_dir)]         \n",
    "\n",
    "        # 存储每一类人的文件夹内所有图片\n",
    "        data[guy] = curr_pics      \n",
    "    return data\n",
    "\n",
    "\n",
    "def read_img(person_dir,f):\n",
    "    img=cv2.imread(pjoin(person_dir, f))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)      \n",
    "    # 判断数组维度\n",
    "\n",
    "\n",
    "    if gray.ndim == 2:\n",
    "        img = to_rgb(gray)\n",
    "    return img\n",
    "\n",
    "# 模型位置\n",
    "model_dir='./20170512-110547'\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        # 加载facenet模型\n",
    "        facenet.load_model(model_dir)\n",
    "\n",
    "        # 返回给定名称的tensor\n",
    "        images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "        embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "        phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "\n",
    "        # 从训练数据文件夹中加载图片并剪裁，最后embding，data为dict\n",
    "        data=load_data('./train_dir/')\n",
    "\n",
    "        # keys列表存储图片文件夹类别（几个人）\n",
    "        keys=[]\n",
    "        for key in data:\n",
    "            keys.append(key)\n",
    "            print('folder:{},image numbers：{}'.format(key,len(data[key])))\n",
    "\n",
    "        # 使用mtcnn模型获取每张图中face的数量以及位置，并将得到的embedding数据存储\n",
    "        for n in range(len(keys)):\n",
    "            for x in data[keys[n]]:\n",
    "                _,images_me,i = load_and_align_data(x, 160, 44, 1.0)\n",
    "                if i:\n",
    "                    feed_dict = { images_placeholder: images_me, phase_train_placeholder:False }\n",
    "                    emb = sess.run(embeddings, feed_dict=feed_dict) \n",
    "                    for xx in range(len(emb)):\n",
    "                        emb=list(emb[xx,:])\n",
    "                        emb.append(keys[n])\n",
    "                        with open('face_feature.csv', \"a+\", newline=\"\") as csvfile:\n",
    "                            writer = csv.writer(csvfile)\n",
    "                            writer.writerow(emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(facial_feature[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dilireba', 'mylove', 'other']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
